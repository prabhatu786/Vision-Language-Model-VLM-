{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC_KiG6Z7uz8"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision transformers pandas requests Pillow tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, clear_output\n",
        "from subprocess import getoutput\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'K80' in s:gpu = 'K80'\n",
        "elif 'T4' in s:gpu = 'T4'\n",
        "elif 'P100' in s:gpu = 'P100'\n",
        "else:\n",
        "    gpu='DONT PROCEED'\n",
        "display(HTML(f\"<h1>{gpu}</h1>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "07IMJFeb7xsU",
        "outputId": "f13f7e85-f5cc-4a68-a45d-73fc401fc7df"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>T4</h1>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## **Importing Necessary Laibrary**"
      ],
      "metadata": {
        "id": "4r-50o4875tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "import os\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "F2JuAsJd7xvd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configuration Parameters**"
      ],
      "metadata": {
        "id": "wBtkgcD28BGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Path to your CSV file containing image URLs\n",
        "CSV_FILE_PATH = '/content/image_url.csv'#'/content/Final_dataset.csv'  # Replace with your actual CSV file path\n",
        "\n",
        "# Batch size for processing images\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# Maximum number of threads for downloading images\n",
        "MAX_WORKERS = 20\n",
        "\n",
        "# Directory to cache downloaded images\n",
        "CACHE_DIR = 'image_cache'\n",
        "\n",
        "# Define your unique categories list\n",
        "data = pd.read_csv('/content/product_category.csv') #('/content/product_category.csv')\n",
        "df = pd.DataFrame(data)\n",
        "# Get unique categories from the 'product_category' column\n",
        "unique_categories = df['Product_category'].unique()\n",
        "# Convert the unique categories to a list\n",
        "unique_categories_list = unique_categories.tolist()\n"
      ],
      "metadata": {
        "id": "GrU2pVD47xye"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Step 1: Data Management**"
      ],
      "metadata": {
        "id": "6svegEqZ8JTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load image URLs from the CSV file into a pandas DataFrame\n",
        "try:\n",
        "    data = pd.read_csv(CSV_FILE_PATH)\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Verify required columns exist\n",
        "    required_columns = ['PRODUCT_MAIN_IMAGE_URL']\n",
        "    for col in required_columns:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"The CSV file must contain a column named '{col}'.\")\n",
        "\n",
        "    print(f\"Successfully loaded {len(df)} image URLs from the CSV file.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"CSV file not found at path: {CSV_FILE_PATH}\")\n",
        "    exit(1)\n",
        "except pd.errors.EmptyDataError:\n",
        "    print(f\"CSV file at {CSV_FILE_PATH} is empty.\")\n",
        "    exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading the CSV file: {e}\")\n",
        "    exit(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDKT6A7k7x1s",
        "outputId": "ad867c74-7f77-4042-8285-84946ad6f1d6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 994 image URLs from the CSV file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Step 2: Image Loading**"
      ],
      "metadata": {
        "id": "yVssyTuq8Ufx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_image_from_url(url, size=(224, 224), retries=3, backoff=5, cache_dir='image_cache'):\n",
        "    \"\"\"\n",
        "    Downloads an image from the given URL, resizes it, and returns a PIL Image.\n",
        "    Implements retries with exponential backoff and caching to avoid re-downloading.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the image.\n",
        "        size (tuple): Desired size to resize the image.\n",
        "        retries (int): Number of retry attempts for failed downloads.\n",
        "        backoff (int): Initial backoff time in seconds.\n",
        "        cache_dir (str): Directory to cache downloaded images.\n",
        "\n",
        "    Returns:\n",
        "        PIL.Image.Image or None: The downloaded and processed image, or None if failed.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(cache_dir):\n",
        "        os.makedirs(cache_dir)\n",
        "\n",
        "    # Create a unique filename based on the URL\n",
        "    # Replace non-filename-friendly characters\n",
        "    filename = os.path.join(cache_dir, os.path.basename(url).split(\"?\")[0])\n",
        "    # Ensure the filename has a valid image extension\n",
        "    if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "        filename += '.jpg'\n",
        "\n",
        "    # Check if the image is already cached\n",
        "    if os.path.exists(filename):\n",
        "        try:\n",
        "            img = Image.open(filename).convert(\"RGB\")\n",
        "            img = img.resize(size)\n",
        "            return img\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading cached image {filename}: {e}\")\n",
        "            # If cached image is corrupted, remove it and re-download\n",
        "            os.remove(filename)\n",
        "\n",
        "    # Attempt to download the image with retries\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "            img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "            img = img.resize(size)\n",
        "            img.save(filename)  # Save to cache\n",
        "            return img\n",
        "        except Exception as e:\n",
        "            print(f\"Attempt {attempt + 1} failed for {url}: {e}\")\n",
        "            time.sleep(backoff * (2 ** attempt))  # Exponential backoff\n",
        "\n",
        "    print(f\"All attempts failed for {url}.\")\n",
        "    return None\n",
        "\n",
        "def download_images(urls, max_workers=20):\n",
        "    \"\"\"\n",
        "    Downloads images in parallel using ThreadPoolExecutor.\n",
        "    \"\"\"\n",
        "    images = [None] * len(urls)\n",
        "\n",
        "    def fetch_image(idx, url):\n",
        "        images[idx] = load_image_from_url(url, size=(224, 224), cache_dir=CACHE_DIR)\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = [executor.submit(fetch_image, idx, url) for idx, url in enumerate(urls)]\n",
        "        for future in as_completed(futures):\n",
        "            pass  # Errors are already handled in load_image_from_url\n",
        "\n",
        "    return images\n"
      ],
      "metadata": {
        "id": "ym4Rg7gc7x5G"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Batch Processing*"
      ],
      "metadata": {
        "id": "Riu3471r8gzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load CLIP model and processor\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "try:\n",
        "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
        "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "except Exception as e:\n",
        "    print(f\"Error loading CLIP model or processor: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "def predict_categories_batch(images, categories, model, processor, device):\n",
        "    if not images:\n",
        "        return []\n",
        "\n",
        "    # Process inputs\n",
        "    try:\n",
        "        inputs = processor(text=categories, images=images, return_tensors=\"pt\", padding=True).to(device)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during processing inputs: {e}\")\n",
        "        return [\"Error\"] * len(images)\n",
        "\n",
        "    # Forward pass\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits_per_image = outputs.logits_per_image  # Shape: (batch_size, num_categories)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during model inference: {e}\")\n",
        "        return [\"Error\"] * len(images)\n",
        "\n",
        "    # Calculate probabilities\n",
        "    try:\n",
        "        probs = logits_per_image.softmax(dim=1).cpu().numpy()  # Shape: (batch_size, num_categories)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during probability calculation: {e}\")\n",
        "        return [\"Error\"] * len(images)\n",
        "\n",
        "    # Get the category with the highest probability for each image\n",
        "    try:\n",
        "        predicted_indices = probs.argmax(axis=1)  # Shape: (batch_size,)\n",
        "        predicted_categories = [categories[idx] for idx in predicted_indices]\n",
        "    except Exception as e:\n",
        "        print(f\"Error during category assignment: {e}\")\n",
        "        predicted_categories = [\"Error\"] * len(images)\n",
        "\n",
        "    return predicted_categories\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQc-EVCq7x8d",
        "outputId": "356566e9-639c-4ac9-d182-080cc9bd8a47"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Step 4: Predict Categories for All Images**"
      ],
      "metadata": {
        "id": "8vcRB2JI8mqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define batch size\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# Initialize a list to store predicted categories\n",
        "predicted_categories = []\n",
        "\n",
        "# Calculate the number of batches\n",
        "num_batches = (len(df) + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "\n",
        "# Iterate over the DataFrame in batches\n",
        "for batch_num in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
        "    start_idx = batch_num * BATCH_SIZE\n",
        "    end_idx = min(start_idx + BATCH_SIZE, len(df))\n",
        "\n",
        "    # Replace 'image_url' with the actual column name containing the image URLs\n",
        "    # For example, if the column is named 'PRODUCT_MAIN_IMAGE_URL', use:\n",
        "    batch_urls = df['PRODUCT_MAIN_IMAGE_URL'].iloc[start_idx:end_idx].tolist()\n",
        "\n",
        "\n",
        "    # Download images in parallel\n",
        "    images = download_images(batch_urls, max_workers=MAX_WORKERS)\n",
        "\n",
        "    # Initialize list for valid images\n",
        "    valid_images = []\n",
        "    valid_indices = []\n",
        "\n",
        "    # Assign predictions\n",
        "    for idx, img in enumerate(images):\n",
        "        if img is not None:\n",
        "            valid_images.append(img)\n",
        "            valid_indices.append(idx)\n",
        "        else:\n",
        "            predicted_categories.append(\"Error\")  # Assign \"Error\" for failed downloads\n",
        "\n",
        "    # Predict categories for valid images\n",
        "    if valid_images:\n",
        "        batch_predictions = predict_categories_batch(valid_images, unique_categories_list, model, processor, device)\n",
        "        # Assign predictions to the corresponding positions\n",
        "        for pred in batch_predictions:\n",
        "            predicted_categories.append(pred)\n",
        "\n",
        "    # Assign \"Error\" for images that failed to load (already done above)\n",
        "    # Ensure the length of predicted_categories matches the DataFrame\n",
        "    while len(predicted_categories) < end_idx:\n",
        "        predicted_categories.append(\"Error\")\n",
        "\n",
        "# Assign the predictions to the DataFrame\n",
        "df['predicted_category'] = predicted_categories[:len(df)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "123SdWBP7x_e",
        "outputId": "81ef2bf7-8252-40cd-cf69-50efadbbad15"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Batches: 100%|██████████| 10/10 [00:16<00:00,  1.61s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Result Storage**"
      ],
      "metadata": {
        "id": "3i0f6k3Q8wF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the DataFrame with predictions to a CSV file\n",
        "output_csv_path = \"product_categories_predictions.csv\"\n",
        "try:\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Predictions saved to {output_csv_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving predictions to CSV: {e}\")\n",
        "\n",
        "# Optional: Display the first few rows of the DataFrame\n",
        "print(df.head(150))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYt9Svcf7yDa",
        "outputId": "45ccfcfd-ee33-4fbc-cd51-dbc7cebf358b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to product_categories_predictions.csv\n",
            "                                PRODUCT_MAIN_IMAGE_URL   predicted_category\n",
            "0    https://content.jdmagicbox.com/quickquotes/ima...    Embroidery Fabric\n",
            "1    https://content.jdmagicbox.com/quickquotes/ima...        Salwar Kameez\n",
            "2    https://content.jdmagicbox.com/quickquotes/ima...   Furniture Hardware\n",
            "3    https://content.jdmagicbox.com/quickquotes/ima...  Sliding Door Roller\n",
            "4    https://content.jdmagicbox.com/quickquotes/ima...  Sliding Door Roller\n",
            "..                                                 ...                  ...\n",
            "145  https://image1.jdomni.in/product/01042022/FD/8...           Key Chains\n",
            "146  https://image1.jdomni.in/product/01042022/66/B...           Key Chains\n",
            "147  https://image1.jdomni.in/product/01042022/8E/8...           Key Chains\n",
            "148  https://image1.jdomni.in/product/01042022/F5/5...           Key Chains\n",
            "149  https://image1.jdomni.in/product/01042022/24/7...           Key Chains\n",
            "\n",
            "[150 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jDi-U5UM7yGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I4z7fsGW7yJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lmLQyiKs7yP5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}